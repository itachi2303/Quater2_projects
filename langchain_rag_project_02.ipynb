{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMCwXxjAfQlrYd44hbMESw2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/itachi2303/Quater2_projects/blob/main/langchain_rag_project_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qk6hOGiJkQj-"
      },
      "outputs": [],
      "source": [
        "%pip install -qU langchain-pinecone langchain-google-genai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pinecone import Pinecone, ServerlessSpec\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "pinecone_api_key = os.environ['PINECONE_API_KEY'] = userdata.get('PINECONE_API_KEY')\n",
        "pc = Pinecone(api_key = pinecone_api_key)"
      ],
      "metadata": {
        "id": "IHocOPMjlUGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "existing_indexes = pc.list_indexes()\n",
        "existing_indexes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QsiVyXZwqIgX",
        "outputId": "862d531b-ba68-46ee-bf2c-99dbc9b5c696"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index_name = \"study-rag-project\"\n",
        "\n",
        "pc.create_index(\n",
        "      name=index_name,\n",
        "      dimension=768,\n",
        "      spec=ServerlessSpec(cloud='aws', region=\"us-east-1\"),\n",
        "      metric=\"cosine\"\n",
        "       )\n",
        "first_index = pc.Index(index_name)"
      ],
      "metadata": {
        "id": "YQE7hHTdpJ9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "\n",
        "# Google_api_key setup\n",
        "os.environ['GOOGLE_API_KEY'] = userdata.get('GOOGLE_API_KEY')\n"
      ],
      "metadata": {
        "id": "wjOEoCvPt5br"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_model = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")"
      ],
      "metadata": {
        "id": "igRG4KWJuUZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector = embedding_model.embed_query(\"hello how are u\")\n",
        "vector[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZJvAxuy0uCm",
        "outputId": "ccb39ba8-5674-4017-f590-576536788bf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0134428096935153,\n",
              " -0.010091329924762249,\n",
              " -0.02226116508245468,\n",
              " -0.008058574050664902,\n",
              " 0.04874265193939209,\n",
              " -0.010381502099335194,\n",
              " 0.018190965056419373,\n",
              " -0.011156506836414337,\n",
              " 0.005312008783221245,\n",
              " 0.00734741473570466]"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "existing_indexes = pc.list_indexes()\n",
        "existing_indexes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "paY_QJU33H6n",
        "outputId": "234f94a3-698e-4b98-a594-cdc9538e171d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\n",
              "    {\n",
              "        \"name\": \"study-rag-project\",\n",
              "        \"dimension\": 768,\n",
              "        \"metric\": \"cosine\",\n",
              "        \"host\": \"study-rag-project-k522enj.svc.aped-4627-b74a.pinecone.io\",\n",
              "        \"spec\": {\n",
              "            \"serverless\": {\n",
              "                \"cloud\": \"aws\",\n",
              "                \"region\": \"us-east-1\"\n",
              "            }\n",
              "        },\n",
              "        \"status\": {\n",
              "            \"ready\": true,\n",
              "            \"state\": \"Ready\"\n",
              "        },\n",
              "        \"deletion_protection\": \"disabled\"\n",
              "    }\n",
              "]"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_pinecone import PineconeVectorStore\n",
        "vectorstore = PineconeVectorStore(index=first_index, embedding=embedding_model)"
      ],
      "metadata": {
        "id": "nUTc8dEB3mGN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from uuid import uuid4\n",
        "\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "document_1 = Document(\n",
        "    page_content=\"I had chocalate chip pancakes and scrambled eggs for breakfast this morning.\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        ")\n",
        "\n",
        "document_2 = Document(\n",
        "    page_content=\"The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.\",\n",
        "    metadata={\"source\": \"news\"},\n",
        ")\n",
        "\n",
        "document_3 = Document(\n",
        "    page_content=\"Building an exciting new project with LangChain - come check it out!\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        ")\n",
        "\n",
        "document_4 = Document(\n",
        "    page_content=\"Robbers broke into the city bank and stole $1 million in cash.\",\n",
        "    metadata={\"source\": \"news\"},\n",
        ")\n",
        "\n",
        "document_5 = Document(\n",
        "    page_content=\"Wow! That was an amazing movie. I can't wait to see it again.\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        ")\n",
        "\n",
        "document_6 = Document(\n",
        "    page_content=\"Is the new iPhone worth the price? Read this review to find out.\",\n",
        "    metadata={\"source\": \"website\"},\n",
        ")\n",
        "\n",
        "document_7 = Document(\n",
        "    page_content=\"The top 10 soccer players in the world right now.\",\n",
        "    metadata={\"source\": \"website\"},\n",
        ")\n",
        "\n",
        "document_8 = Document(\n",
        "    page_content=\"LangGraph is the best framework for building stateful, agentic applications!\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        ")\n",
        "\n",
        "document_9 = Document(\n",
        "    page_content=\"The stock market is down 500 points today due to fears of a recession.\",\n",
        "    metadata={\"source\": \"news\"},\n",
        ")\n",
        "\n",
        "document_10 = Document(\n",
        "    page_content=\"I have a bad feeling I am going to get deleted :(\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        ")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1hTLjJTV5Vm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents = [\n",
        "    document_1,\n",
        "    document_2,\n",
        "    document_3,\n",
        "    document_4,\n",
        "    document_5,\n",
        "    document_6,\n",
        "    document_7,\n",
        "    document_8,\n",
        "    document_9,\n",
        "    document_10,\n",
        "]"
      ],
      "metadata": {
        "id": "LLKgOlsm5duA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uuids = [str(uuid4()) for _ in range(len(documents))]"
      ],
      "metadata": {
        "id": "6CVmFXH15E49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore.add_documents(documents=documents, ids=uuids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrgcV0Ei35e8",
        "outputId": "a7318632-1930-47bd-de9e-85a807a05272"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['7eb3a9e9-260c-4975-b3f4-d75cdfd69d2b',\n",
              " 'cebb2aaf-90d8-4f01-85df-d5d8d76e724d',\n",
              " '0b998fa4-053c-4469-8fe4-653e7ba9c67d',\n",
              " '85dec559-0943-4e25-9f86-8291642656ba',\n",
              " '054d8778-dfbb-4a68-ab20-3bbf98c1d50f',\n",
              " '25441e88-de30-417b-94cb-53ae11b73a81',\n",
              " '3e0496e6-5a07-4235-9b6f-9c5d00af08dc',\n",
              " 'f1c55e98-d3fc-42f5-94a2-10c07b7f45e5',\n",
              " '940bebdc-3bf6-451f-8025-2e5e4a994cf3',\n",
              " '10bef52b-7f76-491b-96e5-649ebd6827ef']"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### deleting an items from vector store"
      ],
      "metadata": {
        "id": "I5uqDc4D7V01"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# vectorstore.delete(ids=[uuids[-1]])"
      ],
      "metadata": {
        "id": "G0-tZnIe7kZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search_query = vectorstore.similarity_search(\n",
        "    \"LangChain provides abstractions to make working with LLMs easy\",\n",
        "    k=2,\n",
        "    filter={\"source\": \"tweet\"},\n",
        ")\n",
        "for res in search_query:\n",
        "    print(f\"* {res.page_content} [{res.metadata}]\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvA5JnoD5qe7",
        "outputId": "16d37539-6179-49f8-b37e-3a2957852e50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "* LangGraph is the best framework for building stateful, agentic applications! [{'source': 'tweet'}]\n",
            "* Building an exciting new project with LangChain - come check it out! [{'source': 'tweet'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = vectorstore.similarity_search_with_score(\n",
        "    \"Will it be hot tomorrow?\",\n",
        ")\n",
        "for res, score in results:\n",
        "    print(f\"* [SIM={score:3f}] {res.page_content} [{res.metadata}]\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-U6EHOGf7PXS",
        "outputId": "ff62a7b4-0b72-45ca-c504-56e1fc7c3dd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "* [SIM=0.667716] The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees. [{'source': 'news'}]\n",
            "* [SIM=0.577374] I have a bad feeling I am going to get deleted :( [{'source': 'tweet'}]\n",
            "* [SIM=0.537337] I had chocalate chip pancakes and scrambled eggs for breakfast this morning. [{'source': 'tweet'}]\n",
            "* [SIM=0.533720] The stock market is down 500 points today due to fears of a recession. [{'source': 'news'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.0-flash-exp\",\n",
        "    temperature=0.7\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "pI3-CI7I-CqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ask(query : str):\n",
        "  query_data = vectorstore.similarity_search(query,k=3)\n",
        "  response = llm.invoke(f\"Answer this query :{query}, Here are some refrences {query_data}\")\n",
        "  return response\n"
      ],
      "metadata": {
        "id": "s_LLYnIv9h_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = ask(\"LangChain provides abstractions to make working with LLMs easy\")\n",
        "print(res.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnbcJz4iAIKs",
        "outputId": "0ac24e03-dc74-4230-c019-b23248dc4ead"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Okay, I understand. You've provided a statement about LangChain making LLM interactions easier, and then given me three documents, each representing a tweet. \n",
            "\n",
            "Here's a breakdown of what we can infer and how it relates to your initial statement:\n",
            "\n",
            "*   **Initial Statement:** \"LangChain provides abstractions to make working with LLMs easy.\" This is a general claim about the purpose of LangChain.\n",
            "\n",
            "*   **Document Analysis:**\n",
            "    *   **Document 1 (ID: f1c55e98...)**: This tweet promotes **LangGraph** as the \"best framework\" for stateful and agentic applications. While LangGraph is related to LangChain, it's not directly about making working with LLMs *easy* in the most basic sense. It speaks to the power and sophistication of a specific part of the LangChain ecosystem. \n",
            "    *   **Document 2 (ID: 0b998fa4...)**: This tweet expresses excitement about building a project with **LangChain**. This tweet supports the idea that people are using LangChain and finding value in it.\n",
            "    *   **Document 3 (ID: 10bef52b...)**: This tweet is irrelevant to the discussion of LangChain. It's a personal statement with no connection to the technology.\n",
            "\n",
            "**Summary and Connection:**\n",
            "\n",
            "*   The provided tweets offer *some* support for the initial statement. The second tweet shows enthusiasm for using LangChain, implying a positive user experience.\n",
            "*   The first tweet is more specific, highlighting LangGraph's capabilities for advanced applications. While not directly about the \"easiness\" of using LLMs, it suggests that the LangChain ecosystem is powerful and enables complex tasks.\n",
            "*   The third tweet is not relevant to the discussion.\n",
            "\n",
            "**Inference:**\n",
            "\n",
            "Based on the provided information, we can infer that:\n",
            "\n",
            "*   LangChain is a popular tool for working with LLMs, as evidenced by the second tweet.\n",
            "*   LangChain has an ecosystem (including LangGraph) that enables both basic and complex applications with LLMs.\n",
            "*   Not all tweets about LangChain are relevant to its ease of use.\n",
            "\n",
            "**In conclusion:** The documents provide some evidence that supports the claim that LangChain is being used. However, the documents do not directly illustrate how LangChain provides abstractions to make working with LLMs easy, but rather that it is being used and that there are other related tools.\n"
          ]
        }
      ]
    }
  ]
}